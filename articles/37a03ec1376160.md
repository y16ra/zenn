---
title: "OpenAIの Assistants APIでVector Storeを使った実装を試してみた"
emoji: "🌊"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["ai", "openai", "openaiapi"]
published: true
---

## はじめに

OpenAI の Assistants API について調査したので、その内容を共有します。
Assistants API は現在ベータ版で提供されているAPIです。
ベータ版なので記事で書いている内容が変更されている可能性がありますのでご了承ください。

https://platform.openai.com/docs/assistants/overview

## Assistants API の概要

Assistantsには、以下の項目を設定できます。
- System instructions
- Model
- Tools

利用できるToolsには以下のものがあります。
- Code Interpreter
- File Search
- Function Calling

コンソール画面のUIを見るとわかりやすいです。
![openai-console-assistants](/images/articles/37a03ec1376160/openai-console-assistants.png =400x)
*OpenAIのコンソール画面*

## Assistants API の使い方

![](https://cdn.openai.com/API/docs/images/diagram-assistant.webp)

1. Assistant: 名前、使用するモデル、ツールを指定して作成します。
1. Thread: 会話のスレッドを管理します。
1. Message: ユーザとアシスタントのメッセージです。Threadにリストで保管されます。
1. Run: Thread上でAssistantを実行します。

今回はFile Searchツールを使ってVector Storeに登録されたデータを使って回答するAssistantを作成します。
今回はVector Storeは管理コンソールから事前に登録しました。
以下のような画面でファイルをアップロードすればVector Storeにデータが登録されます。

![](/images/articles/37a03ec1376160/vector-store.png)

### Assistant の作成
Assistantは用途ごとに作成します。
APIで作成できますが管理コンソールで作成してIDを取得して使うのでも良いと思います。

```python
assistant = client.beta.assistants.create(
    name="AI File Search Assistant",
    instructions="あなたはAIアシスタントです。指示がなければ日本語で回答します。",
    model="gpt-4o",
    tools=[{"type": "file_search"}],
    tool_resources={"file_search": {"vector_store_ids": [VECTOR_STORE_ID]}},
)
```

### Thread の作成

空のThreadを作成します。

```python
thread = client.beta.threads.create()
```

Threadには回答のMessageも自動で登録されますので、リクエストの度に全ての会話履歴をパラメータで渡す必要はありません。
`thread.id` を使ってメッセージを追加して実行することができるので便利です。

### Message の作成

先ほど作成したThreadにメッセージを追加します。

```python
prompt = "XXXXについて教えてください。"
thread_message = client.beta.threads.messages.create(
    thread.id,
    role="user",
    content=prompt,
)
```

### Assistant の実行

作成したThread上でAssistantを実行します。

```python
run = client.beta.threads.runs.create(
    thread_id=thread.id,
    assistant_id=assistant_id,
)
while True:
    run = client.beta.threads.runs.retrieve(
        thread_id=thread.id,
        run_id=run.id
    )
    if run.status == "completed":
        break
    time.sleep(1)
```

### 結果の取得

status が completed になったら結果を取得します。

```python
thread_messages = client.beta.threads.messages.list(thread_id)
if thread_messages[0].content[0].type == "text":
  print(thread_messages[0].content[0].text.value)
```

## まとめ

OpenAIのAssistants APIを使って手軽にRAGのような一般に公開されていない情報や最新の情報を使った質問応答システムを作成することができます。
Amazon Bedrock のナレッジベースでも同様の機能を実装することができますがVector Storeの管理がOpenAIの方が簡単でした。
自分の用途にあったデータをVector Storeに登録して使いこなせると色々と捗りそうです。

今回の動作確認はPythonで行いました。書いたコードは以下のリポジトリにありますので参考にしてください。
https://github.com/y16ra/openai-assistants-sample

## おまけ

プロンプトの書き方については、以下のサイトが参考になります。
https://platform.openai.com/docs/guides/prompt-engineering
https://www.promptingguide.ai/jp
